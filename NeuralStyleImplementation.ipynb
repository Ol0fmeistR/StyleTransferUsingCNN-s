{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom keras import backend as K  #so that the keras module is compatible with both theano and tensorflow\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications import VGG16\n#from IPython.display import Image\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.layers import Input\nfrom scipy.optimize import fmin_l_bfgs_b  #optimization algo to optimize the losses and gradients",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Specifying path for content, style and generated image\ncImPath = \"../input/new-data/c.jpeg\"\nsImPath = \"../input/new-data/s.jpeg\"",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "461678c79aa953bab836abb0502725752afbba48",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Image processing\ntargetHeight = 512\ntargetWidth = 512\ntargetSize = (targetHeight, targetWidth)\n\ncImage = load_img(path=cImPath,target_size=targetSize)\ncImArr = img_to_array(cImage)\ncImArr = K.variable(preprocess_input(np.expand_dims(cImArr, axis=0)), dtype='float32')\n\nsImage = load_img(path=sImPath, target_size=targetSize)\nsImArr = img_to_array(sImage)\nsImArr = K.variable(preprocess_input(np.expand_dims(sImArr, axis=0)), dtype='float32')\n\ngIm0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\ngIm0 = preprocess_input(np.expand_dims(gIm0, axis=0))\ngImPlaceholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6c0a0451f1f12be81036ac0cf11afc363396582f"
      },
      "cell_type": "code",
      "source": "#defining the content loss function\ndef get_feature_reps(x, layer_names, model):\n    \"\"\"\n    Get feature representations of input x for one or more layers in a given model.\n    \"\"\"\n    featMatrices = []\n    for ln in layer_names:\n        selectedLayer = model.get_layer(ln)\n        featRaw = selectedLayer.output\n        featRawShape = K.shape(featRaw).eval(session=tf_session)\n        N_l = featRawShape[-1]\n        M_l = featRawShape[1]*featRawShape[2]\n        featMatrix = K.reshape(featRaw, (M_l, N_l))\n        featMatrix = K.transpose(featMatrix)\n        featMatrices.append(featMatrix)\n    return featMatrices\n\ndef get_content_loss(F, P):\n    cLoss = 0.5*K.sum(K.square(F - P))\n    return cLoss",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4abd1c49f7d0aa0f69fc4890acc896ad9df0d49f"
      },
      "cell_type": "code",
      "source": "#defining the gram matrix\ndef get_Gram_matrix(F):\n    G = K.dot(F, K.transpose(F))\n    return G",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b7c1f163334b34cd976417c103abb1545d7fa7a7"
      },
      "cell_type": "code",
      "source": "#defining the style loss function\ndef get_style_loss(ws, Gs, As):\n    sLoss = K.variable(0.)\n    for w, G, A in zip(ws, Gs, As):\n        M_1 = K.int_shape(G)[1]\n        N_1 = K.int_shape(G)[0]\n        G_gram = get_Gram_matrix(G)\n        A_gram = get_Gram_matrix(A)\n        sLoss = sLoss + w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_1**2 * M_1**2)\n    return sLoss",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f33cf914d2077cd2d7595dab5fe7b7195b4cc815"
      },
      "cell_type": "code",
      "source": "#Combining both content and style loss functions together\ndef get_total_loss(gImPlaceholder, alpha=10, beta=3000):\n    F = get_feature_reps(gImPlaceholder, layer_names=[cLayerName], model=gModel)[0]\n    Gs = get_feature_reps(gImPlaceholder, layer_names=sLayerNames, model=gModel)\n    contentLoss = get_content_loss(F, P)\n    styleLoss = get_style_loss(ws, Gs, As)\n    totalLoss = alpha*contentLoss + beta*styleLoss\n    return totalLoss",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "1cd0a625fe1ee234127687802d7e8bb69987fb06",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Calculating gradients and minimizing loss function using scipy's L-BFGS-B algorithm\ndef calculate_loss(gImArr):\n    if gImArr.shape != (1, targetWidth, targetWidth, 3):\n        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n    loss_fcn = K.function([gModel.input], [get_total_loss(gModel.input)])\n    return loss_fcn([gImArr])[0].astype('float64')\n\ndef get_grad(gImArr):\n    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n    grad_fcn = K.function([gModel.input], \n                          K.gradients(get_total_loss(gModel.input), [gModel.input]))\n    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n    return grad\n\nfrom keras.applications import VGG16\nfrom scipy.optimize import fmin_l_bfgs_b\n\ntf_session = K.get_session()\ncModel = VGG16(include_top=False, weights='../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', input_tensor=cImArr)\nsModel = VGG16(include_top=False, weights='../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', input_tensor=sImArr)\ngModel = VGG16(include_top=False, weights='../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', input_tensor=gImPlaceholder)\ncLayerName = 'block4_conv2'\nsLayerNames = [\n                'block1_conv1',\n                'block2_conv1',\n                'block3_conv1',\n                'block4_conv1',\n                ]\n\nP = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]\nAs = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)\nws = np.ones(len(sLayerNames))/float(len(sLayerNames))\n\niterations = 250\nx_val = gIm0.flatten()\nxopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n                            maxiter=iterations, disp=True)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7b092ec8c7c925d0cbe7b1f81ce6db906622ebe",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2579f835af64ddbf9d786f2f3edd2d8130e067af",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def postprocess_array(x):\n    # Zero-center by mean pixel\n    if x.shape != (targetWidth, targetHeight, 3):\n        x = x.reshape((targetWidth, targetHeight, 3))\n    x[..., 0] += 103.939\n    x[..., 1] += 116.779\n    x[..., 2] += 123.68\n    # 'BGR'->'RGB'\n    x = x[..., ::-1]\n    x = np.clip(x, 0, 255)\n    x = x.astype('uint8')\n    return x",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2b930127a53d1d71354d203ee684e0214097b302"
      },
      "cell_type": "code",
      "source": "def reprocess_array(x):\n    x = np.expand_dims(x.astype('float64'), axis=0)\n    x = preprocess_input(x)\n    return x",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ac024a4cc7446dc617bcfd24420cf47e3149b4b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cImageOrig = Image.open(cImPath)\ncImageSizeOrig = cImageOrig.size",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "037ba39afaacd18b05856e17bd49c3f1f292e7cf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def save_original_size(x, target_size=cImageSizeOrig):\n    xIm = Image.fromarray(x)\n    xIm = xIm.resize(target_size)\n    xIm.save(fp = 'result.png' ,format='PNG')\n    return xIm",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e56b1caf43fcfce9656aab5032699c0878e660dd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xOut = postprocess_array(xopt)\nxIm = save_original_size(xOut)\nprint ('Image saved')",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c54e380b0c5a9f1127c47da128ad4c287421afaf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}